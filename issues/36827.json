{
  "url": "https://api.github.com/repos/quarkusio/quarkus/issues/36827",
  "repository_url": "https://api.github.com/repos/quarkusio/quarkus",
  "labels_url": "https://api.github.com/repos/quarkusio/quarkus/issues/36827/labels{/name}",
  "comments_url": "https://api.github.com/repos/quarkusio/quarkus/issues/36827/comments",
  "events_url": "https://api.github.com/repos/quarkusio/quarkus/issues/36827/events",
  "html_url": "https://github.com/quarkusio/quarkus/issues/36827",
  "id": 1973961087,
  "node_id": "I_kwDOCFbutM51qEF_",
  "number": 36827,
  "title": "[Extension Proposal] OpenAI client extension",
  "labels": [
    {
      "id": 1553869078,
      "node_id": "MDU6TGFiZWwxNTUzODY5MDc4",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/kind/extension-proposal",
      "name": "kind/extension-proposal",
      "color": "abfcbb",
      "default": false,
      "description": "Discuss and Propose new extensions"
    },
    {
      "id": 2388070055,
      "node_id": "MDU6TGFiZWwyMzg4MDcwMDU1",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/area/quarkiverse",
      "name": "area/quarkiverse",
      "color": "a01441",
      "default": false,
      "description": "This issue/PR is part of the Quarkiverse organization"
    }
  ],
  "state": "closed",
  "locked": false,
  "milestone": null,
  "comments": 8,
  "created_at": "2023-11-02T10:36:12Z",
  "updated_at": "2024-05-13T03:36:33Z",
  "closed_at": "2024-05-13T03:36:33Z",
  "active_lock_reason": null,
  "body": "### Description\r\n\r\nDue to the high adoption of generative models, an higher level API could be very useful to integrate Quarkus applications to OpenAI services.\r\n\r\nThe idea is to configure, at least, few parameters, like the model to use, and inject a ready to use provider bean, something like:\r\n\r\n```\r\nquarkus.openai.api-key=sk-vB...4uWF\r\nquarkus.openai.gpt.stream=true\r\nquarkus.openai.gpt.chat.model=gpt-3.5-turbo\r\n```\r\n\r\nAdditional configuration entries can be added furthermore from a detailed tuning of the request, like the maximum number of tokens to generate, to technical aspects, like the HTTP client pool. \r\n\r\nE.g. the streaming configuration of the example is optional with a valuable default to false.\r\n\r\n```java\r\n//...\r\n    @Inject\r\n    OpenAIClient aiClient;\r\n\r\n    @GET\r\n    @Path(\"/chat\")\r\n    @RestStreamElementType(MediaType.APPLICATION_JSON)\r\n    public Multi<? extends AbstractOpenAIResponse> chat() {\r\n        var builderTemplate = Message.Builder.of();\r\n        return aiClient.chat().create(List.of(\r\n                builderTemplate\r\n                        .withContent(\"As a test execution to understand if the java client API is properly working\")\r\n                        .withRole(Role.system)\r\n                        .build(),\r\n                builderTemplate\r\n                        .withContent(\"Use very few words to limit the token consumption of OpenAI APIs.\")\r\n                        .withRole(Role.system)\r\n                        .build(),\r\n                builderTemplate\r\n                        .withContent(\r\n                                \"Hello, my name is Test, tell me, in few words, a very short story with at least 2 paragraphs\")\r\n                        .withRole(Role.user)\r\n                        .build()));\r\n    }\r\n//...\r\n```\r\n\r\nThe OpenAIClient acts as a provider for each OpenAI service:\r\n\r\n- to create chat through the chat endpoint\r\n- moderations\r\n- embeddings\r\n- ...\r\nand so on as listed by https://platform.openai.com/docs/api-reference/chat\r\n\r\nEach service is a fa√ßade to the actual/available operations/endpoints of OpenAI services\r\n\r\nThe reactive implementation is the choice because of the current widespread programming model in quarkus, a non-reactive version could be proposed in future if the need emerges.\r\n\r\n### Repository name\r\n\r\nquarkus-openai-client-reactive\r\n\r\n### Short description\r\n\r\nEasily integrate to OpenAI services\r\n\r\n### Repository Homepage URL\r\n\r\nhttps://quarkiverse.github.io/quarkiverse-docs/quarkus-openai-client-reactive/dev/\r\n\r\n### Repository Topics\r\n\r\n- quarkus-extension\r\n- openai\r\n- chatgpt\r\n- llm\r\n\r\n### Team Members\r\n\r\n- I'm available to maintain this extension\r\n\r\n\r\n### Additional context\r\n\r\n_No response_",
  "reactions": {
    "url": "https://api.github.com/repos/quarkusio/quarkus/issues/36827/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/quarkusio/quarkus/issues/36827/timeline",
  "performed_via_github_app": null,
  "state_reason": "not_planned"
}
