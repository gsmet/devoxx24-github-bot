{
  "url": "https://api.github.com/repos/quarkusio/quarkus/issues/32546",
  "repository_url": "https://api.github.com/repos/quarkusio/quarkus",
  "labels_url": "https://api.github.com/repos/quarkusio/quarkus/issues/32546/labels{/name}",
  "comments_url": "https://api.github.com/repos/quarkusio/quarkus/issues/32546/comments",
  "events_url": "https://api.github.com/repos/quarkusio/quarkus/issues/32546/events",
  "html_url": "https://github.com/quarkusio/quarkus/issues/32546",
  "id": 1662753297,
  "node_id": "I_kwDOCFbutM5jG5oR",
  "number": 32546,
  "title": "ResteasyReactiveOutputStream could make better use of the Netty (direct) pooled allocator",
  "labels": [
    {
      "id": 985346622,
      "node_id": "MDU6TGFiZWw5ODUzNDY2MjI=",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/kind/enhancement",
      "name": "kind/enhancement",
      "color": "a2eeef",
      "default": false,
      "description": "New feature or request"
    },
    {
      "id": 2552031458,
      "node_id": "MDU6TGFiZWwyNTUyMDMxNDU4",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/area/rest",
      "name": "area/rest",
      "color": "0366d6",
      "default": false,
      "description": ""
    }
  ],
  "state": "closed",
  "locked": false,
  "milestone": {
    "url": "https://api.github.com/repos/quarkusio/quarkus/milestones/250",
    "html_url": "https://github.com/quarkusio/quarkus/milestone/250",
    "labels_url": "https://api.github.com/repos/quarkusio/quarkus/milestones/250/labels",
    "id": 9407630,
    "node_id": "MI_kwDOCFbutM4Aj4yO",
    "number": 250,
    "title": "3.2.0.CR1",
    "description": "",
    "creator": {
      "login": "gsmet",
      "id": 1279749,
      "node_id": "MDQ6VXNlcjEyNzk3NDk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1279749?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gsmet",
      "html_url": "https://github.com/gsmet",
      "followers_url": "https://api.github.com/users/gsmet/followers",
      "following_url": "https://api.github.com/users/gsmet/following{/other_user}",
      "gists_url": "https://api.github.com/users/gsmet/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gsmet/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gsmet/subscriptions",
      "organizations_url": "https://api.github.com/users/gsmet/orgs",
      "repos_url": "https://api.github.com/users/gsmet/repos",
      "events_url": "https://api.github.com/users/gsmet/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gsmet/received_events",
      "type": "User",
      "site_admin": false
    },
    "open_issues": 0,
    "closed_issues": 244,
    "state": "closed",
    "created_at": "2023-05-17T07:29:12Z",
    "updated_at": "2023-11-15T13:59:38Z",
    "due_on": null,
    "closed_at": "2023-06-21T13:08:09Z"
  },
  "comments": 17,
  "created_at": "2023-04-11T15:29:23Z",
  "updated_at": "2023-05-29T12:23:00Z",
  "closed_at": "2023-05-29T12:22:54Z",
  "active_lock_reason": null,
  "body": "### Description\r\n\r\n`quarkus.resteasy-reactive.output-buffer-size` (see [quarkus.resteasy-reactive.output-buffer-size](https://quarkus.io/guides/all-config#quarkus-resteasy-reactive-common_quarkus.resteasy-reactive.output-buffer-size)'s doc) seems to not just control when responses should contain the `Content-Length` header and being chunked, but the initial eagerly allocated capacity of the buffer used to stream content over the connection per response as well, see https://github.com/quarkusio/quarkus/blob/f6851e3371bf3b28c394a186964b1625f8be5ce2/independent-projects/resteasy-reactive/server/vertx/src/main/java/org/jboss/resteasy/reactive/server/vertx/ResteasyReactiveOutputStream.java#L208\r\n\r\nThis \"eager\" behavior, despite seems optimal while simple (because it allows to perform optimistic batching) can be problematic for the Netty allocator, due to how it works under the hood. \r\nAdding more notes below, to explain the effects/consequences.\r\n\r\n**NOTE**:\r\nthe default buffer size is `8191` bytes \r\n\r\neg\r\n\r\nPerforming an allocation of 8K and assuming a I/O caller thread (aka the event loop), in a default configured Netty scenario, is going to use the netty `PoolThreadCache` at https://github.com/netty/netty/blob/c353f4fea52559d09b3811492c92a38aa1887501/buffer/src/main/java/io/netty/buffer/PoolThreadCache.java#L299-L303 ie a so-called `small` direct pooled allocation.\r\n\r\nThe cache itself is organized in order to have few `MemoryRegionCache`s (in an array) chosen based on the normalized required capacity; in this case it's going to use the one at the `sizeIdx = 31`, obtained by (https://github.com/netty/netty/blob/eb3feb479826949090a9a55c782722ece9b42e50/buffer/src/main/java/io/netty/buffer/SizeClasses.java#L317)[SizeClasses::size2SizeIdx].\r\n\r\nEvery `MemoryRegionCache` has a finite number of pooled (and thread local) buffers ie `io.netty.allocator.smallCacheSize` , which is 256 by default.\r\n\r\nSuch pooled and thread local instances are not filled into `MemoryRegionCache` till they are used/allocated the very first time (on demand) - it means that in the worst case; given that we *always* allocate 8K chunks, we risk to have a (8K * 256) memory footprint per even loop thread, while idle, if a previous run has caused them to be fully allocated (maybe because of 256 concurrent and slow connections running on the same event loop thread).\r\n\r\nIn short: the problem is not the allocation cost, because, in the happy path is a cached already-happened thread-local allocation, but is a matter of idle memory footprint and bad utilization of the existing caching behavior provided by Netty: if we could use different sized allocations here, we can make uses of all the different `sizeIdx` that Netty provide, possibly reducing the idle utilization as well due to retaining just the effectively used ones (or near to what has been the effective usage).\r\nIn addition, using many `MemoryRegionCache` entries, reduce the chances of un-happy paths, because we are not bounded just to a single `MemoryRegionCache` capacity (that's fairly low, as said - just 256 buffers).\r\n\r\n\r\n### Implementation ideas\r\n\r\nhttps://github.com/franz1981/quarkus/tree/append_buffer",
  "reactions": {
    "url": "https://api.github.com/repos/quarkusio/quarkus/issues/32546/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/quarkusio/quarkus/issues/32546/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
