{
  "url": "https://api.github.com/repos/quarkusio/quarkus/issues/31650",
  "repository_url": "https://api.github.com/repos/quarkusio/quarkus",
  "labels_url": "https://api.github.com/repos/quarkusio/quarkus/issues/31650/labels{/name}",
  "comments_url": "https://api.github.com/repos/quarkusio/quarkus/issues/31650/comments",
  "events_url": "https://api.github.com/repos/quarkusio/quarkus/issues/31650/events",
  "html_url": "https://github.com/quarkusio/quarkus/issues/31650",
  "id": 1613213461,
  "node_id": "I_kwDOCFbutM5gJ68V",
  "number": 31650,
  "title": "Compiling Avro as part of other build causes kafka (de)serialisation failures",
  "labels": [
    {
      "id": 985346620,
      "node_id": "MDU6TGFiZWw5ODUzNDY2MjA=",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/kind/bug",
      "name": "kind/bug",
      "color": "d73a4a",
      "default": false,
      "description": "Something isn't working"
    },
    {
      "id": 985346625,
      "node_id": "MDU6TGFiZWw5ODUzNDY2MjU=",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/triage/invalid",
      "name": "triage/invalid",
      "color": "e4e669",
      "default": false,
      "description": "This doesn't seem right"
    },
    {
      "id": 1287515315,
      "node_id": "MDU6TGFiZWwxMjg3NTE1MzE1",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/area/kotlin",
      "name": "area/kotlin",
      "color": "0366d6",
      "default": false,
      "description": ""
    },
    {
      "id": 1658790125,
      "node_id": "MDU6TGFiZWwxNjU4NzkwMTI1",
      "url": "https://api.github.com/repos/quarkusio/quarkus/labels/area/kafka",
      "name": "area/kafka",
      "color": "0366d6",
      "default": false,
      "description": ""
    }
  ],
  "state": "closed",
  "locked": false,
  "milestone": null,
  "comments": 5,
  "created_at": "2023-03-07T11:05:03Z",
  "updated_at": "2023-09-25T08:23:37Z",
  "closed_at": "2023-09-25T08:23:24Z",
  "active_lock_reason": null,
  "body": "### Describe the bug\n\nWe are currently using quarkus `2.4.1.Final` for this project and are trying to upgrade to the latest version but we are having issues with the changes that have occurred with how AVRO is handled.\r\n\r\nWe are using gradle with a number of subprojects. As these services defined by these subprojects tend to communicate over kafka we separated out the avro (along with some related Java classes) to it's own subproject which the consumers and producers then add as an implementation dependency. Unfortunately when we try this on newer version of quarkus, specifically those that print an error message requiring us to import the quarkus-confluent-registry-avro extension things break.This seems to be after Quarkus `2.8`\r\n\r\n\n\n### Expected behavior\n\nIf the avro files have been compiled as part of a separate build that is included as an implementation dependency then you should be able to send and receive messages over kafka using these generated classes.\n\n### Actual behavior\n\nThe error we are encountering is different from the one I managed to create in a reproducer. My original error (and the one I can still get in the real repository) is as follows. Note I have changed the package of the Transaction event package.\r\n\r\n```\r\n       io.smallrye.mutiny.CompositeException: Multiple exceptions caught:\r\n    \t[Exception 0] java.lang.ClassCastException: class org.acme.kafka.TransactionEvent cannot be cast to class org.apache.avro.specific.SpecificRecord (org.acme.kafka.TransactionEvent is in unnamed module of loader 'app'; org.apache.avro.specific.SpecificRecord is in unnamed module of loader io.quarkus.bootstrap.classloading.QuarkusClassLoader @4642b71d)\r\n    \t[Exception 1] it.kahoot.exception.KafkaDeserializationFailure: Unable to deserialise message on kahoot.marketplace.transactions.v1\r\n    \tat io.smallrye.mutiny.operators.uni.UniOnFailureFlatMap$UniOnFailureFlatMapProcessor.performInnerSubscription(UniOnFailureFlatMap.java:94)\r\n    \tat io.smallrye.mutiny.operators.uni.UniOnFailureFlatMap$UniOnFailureFlatMapProcessor.dispatch(UniOnFailureFlatMap.java:83)\r\n    \tat io.smallrye.mutiny.operators.uni.UniOnFailureFlatMap$UniOnFailureFlatMapProcessor.onFailure(UniOnFailureFlatMap.java:60)\r\n    \tat io.smallrye.mutiny.operators.uni.builders.UniCreateFromItemSupplier.subscribe(UniCreateFromItemSupplier.java:31)\r\n    \tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\r\n    \tat io.smallrye.mutiny.operators.uni.UniOnFailureFlatMap.subscribe(UniOnFailureFlatMap.java:31)\r\n    \tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\r\n    \tat io.smallrye.mutiny.operators.uni.UniBlockingAwait.await(UniBlockingAwait.java:60)\r\n    \tat io.smallrye.mutiny.groups.UniAwait.atMost(UniAwait.java:65)\r\n    \tat io.smallrye.mutiny.groups.UniAwait.indefinitely(UniAwait.java:46)\r\n    \tat io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler.decorateDeserialization(DeserializationFailureHandler.java:93)\r\n    \tat io.smallrye.reactive.messaging.kafka.EventDeserializationFailureConfiguration_ProducerMethod_marketplaceUserPurchasesEventFailureHandler_28c0809e750e7edf6bbc6fa9604cf28a96f673a3_ClientProxy.decorateDeserialization(Unknown Source)\r\n    \tat io.smallrye.reactive.messaging.kafka.fault.DeserializerWrapper.wrapDeserialize(DeserializerWrapper.java:94)\r\n    \tat io.smallrye.reactive.messaging.kafka.fault.DeserializerWrapper.deserialize(DeserializerWrapper.java:74)\r\n    \tat org.apache.kafka.clients.consumer.internals.Fetcher.parseRecord(Fetcher.java:1439)\r\n    \tat org.apache.kafka.clients.consumer.internals.Fetcher.access$3400(Fetcher.java:135)\r\n    \tat org.apache.kafka.clients.consumer.internals.Fetcher$CompletedFetch.fetchRecords(Fetcher.java:1671)\r\n    \tat org.apache.kafka.clients.consumer.internals.Fetcher$CompletedFetch.access$1900(Fetcher.java:1507)\r\n    \tat org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords(Fetcher.java:733)\r\n    \tat org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:684)\r\n    \tat org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1304)\r\n    \tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1238)\r\n    \tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1211)\r\n    \tat io.smallrye.reactive.messaging.kafka.impl.ReactiveKafkaConsumer.lambda$poll$4(ReactiveKafkaConsumer.java:141)\r\n    \tat io.smallrye.reactive.messaging.kafka.impl.ReactiveKafkaConsumer.lambda$runOnPollingThread$0(ReactiveKafkaConsumer.java:108)\r\n    \tat io.smallrye.context.impl.wrappers.SlowContextualSupplier.get(SlowContextualSupplier.java:21)\r\n    \tat io.smallrye.mutiny.operators.uni.builders.UniCreateFromItemSupplier.subscribe(UniCreateFromItemSupplier.java:28)\r\n    \tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\r\n    \tat io.smallrye.mutiny.operators.uni.UniRunSubscribeOn.lambda$subscribe$0(UniRunSubscribeOn.java:27)\r\n    \tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\r\n    \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n    \tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\r\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n    \tat java.base/java.lang.Thread.run(Thread.java:833)\r\n    \tSuppressed: it.kahoot.exception.KafkaDeserializationFailure: Unable to deserialise message on kahoot.marketplace.transactions.v1\r\n    \t\tat it.kahoot.marketplace.event.deserialization.EventDeserializationFailureHandler.handleDeserializationFailure(EventDeserializationHandlers.kt:41)\r\n    \t\tat io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler.lambda$decorateDeserialization$0(DeserializationFailureHandler.java:90)\r\n    \t\tat io.smallrye.context.impl.wrappers.SlowContextualFunction.apply(SlowContextualFunction.java:21)\r\n    \t\tat io.smallrye.mutiny.groups.UniOnFailure.lambda$recoverWithItem$8(UniOnFailure.java:190)\r\n    \t\tat io.smallrye.mutiny.operators.uni.UniOnFailureFlatMap$UniOnFailureFlatMapProcessor.performInnerSubscription(UniOnFailureFlatMap.java:92)\r\n    \t\t... 34 more\r\n    \tCaused by: java.lang.ClassCastException: class org.acme.kafka.TransactionEvent cannot be cast to class org.apache.avro.specific.SpecificRecord (org.acme.kafka.TransactionEvent is in unnamed module of loader 'app'; org.apache.avro.specific.SpecificRecord is in unnamed module of loader io.quarkus.bootstrap.classloading.QuarkusClassLoader @4642b71d)\r\n    \t\tat io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer.getSpecificReaderSchema(AbstractKafkaAvroDeserializer.java:250)\r\n    \t\tat io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer.getReaderSchema(AbstractKafkaAvroDeserializer.java:227)\r\n    \t\tat io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer.getDatumReader(AbstractKafkaAvroDeserializer.java:182)\r\n    \t\tat io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer$DeserializationContext.read(AbstractKafkaAvroDeserializer.java:347)\r\n    \t\tat io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer.deserialize(AbstractKafkaAvroDeserializer.java:100)\r\n    \t\tat io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer.deserialize(AbstractKafkaAvroDeserializer.java:79)\r\n    \t\tat io.confluent.kafka.serializers.KafkaAvroDeserializer.deserialize(KafkaAvroDeserializer.java:55)\r\n    \t\tat org.apache.kafka.common.serialization.Deserializer.deserialize(Deserializer.java:60)\r\n    \t\tat io.smallrye.reactive.messaging.kafka.fault.DeserializerWrapper.lambda$deserialize$1(DeserializerWrapper.java:74)\r\n    \t\tat io.smallrye.context.impl.wrappers.SlowContextualSupplier.get(SlowContextualSupplier.java:21)\r\n    \t\tat io.smallrye.mutiny.operators.uni.builders.UniCreateFromItemSupplier.subscribe(UniCreateFromItemSupplier.java:28)\r\n    \t\t... 31 more\r\n    Caused by: [CIRCULAR REFERENCE: java.lang.ClassCastException: class org.acme.kafka.TransactionEvent cannot be cast to class org.apache.avro.specific.SpecificRecord (org.acme.kafka.TransactionEvent is in unnamed module of loader 'app'; org.apache.avro.specific.SpecificRecord is in unnamed module of loader io.quarkus.bootstrap.classloading.QuarkusClassLoader @4642b71d)]\r\n\r\n```\r\n\r\nThe reproducer gives the error below and although it is different it is still related to the (de)serialisation process when the only difference seems to be the classes being compiled in a separate subproject.\r\n\r\n```\r\n2023-03-07 10:25:50,213 ERROR [io.sma.rea.mes.kafka] (smallrye-kafka-producer-thread-0) SRMSG18260: Unable to recover from the serialization failure (topic: movies), configure a SerializationFailureHandler to recover from errors.: java.lang.RuntimeException: com.fasterxml.jackson.databind.JsonMappingException: Not an array: {\"type\":\"record\",\"name\":\"Movie\",\"namespace\":\"org.acme.kafka.quarkus\",\"fields\":[{\"name\":\"title\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"year\",\"type\":\"int\"}]} (through reference chain: org.acme.kafka.quarkus.Movie[\"schema\"]->org.apache.avro.Schema$RecordSchema[\"elementType\"])\r\n\tat io.quarkus.kafka.client.serialization.ObjectMapperSerializer.serialize(ObjectMapperSerializer.java:47)\r\n\tat org.apache.kafka.common.serialization.Serializer.serialize(Serializer.java:62)\r\n\tat io.smallrye.reactive.messaging.kafka.fault.SerializerWrapper.lambda$serialize$1(SerializerWrapper.java:56)\r\n\tat io.smallrye.reactive.messaging.kafka.fault.SerializerWrapper.wrapSerialize(SerializerWrapper.java:81)\r\n\tat io.smallrye.reactive.messaging.kafka.fault.SerializerWrapper.serialize(SerializerWrapper.java:56)\r\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1005)\r\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:952)\r\n\tat io.smallrye.reactive.messaging.kafka.impl.ReactiveKafkaProducer.lambda$send$4(ReactiveKafkaProducer.java:150)\r\n\tat io.smallrye.context.impl.wrappers.SlowContextualConsumer.accept(SlowContextualConsumer.java:21)\r\n\tat io.smallrye.mutiny.operators.uni.builders.UniCreateWithEmitter.subscribe(UniCreateWithEmitter.java:22)\r\n\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\r\n\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.performInnerSubscription(UniOnItemTransformToUni.java:81)\r\n\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.onItem(UniOnItemTransformToUni.java:57)\r\n\tat io.smallrye.mutiny.operators.uni.UniOperatorProcessor.onItem(UniOperatorProcessor.java:47)\r\n\tat io.smallrye.mutiny.operators.uni.UniMemoizeOp.subscribe(UniMemoizeOp.java:73)\r\n\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\r\n\tat io.smallrye.mutiny.operators.uni.UniRunSubscribeOn.lambda$subscribe$0(UniRunSubscribeOn.java:27)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\nCaused by: com.fasterxml.jackson.databind.JsonMappingException: Not an array: {\"type\":\"record\",\"name\":\"Movie\",\"namespace\":\"org.acme.kafka.quarkus\",\"fields\":[{\"name\":\"title\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"year\",\"type\":\"int\"}]} (through reference chain: org.acme.kafka.quarkus.Movie[\"schema\"]->org.apache.avro.Schema$RecordSchema[\"elementType\"])\r\n\tat com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:402)\r\n\tat com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:361)\r\n\tat com.fasterxml.jackson.databind.ser.std.StdSerializer.wrapAndThrow(StdSerializer.java:316)\r\n\tat com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:782)\r\n\tat com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:178)\r\n\tat com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:733)\r\n\tat com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:774)\r\n\tat com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:178)\r\n\tat com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:480)\r\n\tat com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:319)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._writeValueAndClose(ObjectMapper.java:4624)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:3828)\r\n\tat io.quarkus.kafka.client.serialization.ObjectMapperSerializer.serialize(ObjectMapperSerializer.java:44)\r\n\t... 19 more\r\nCaused by: org.apache.avro.AvroRuntimeException: Not an array: {\"type\":\"record\",\"name\":\"Movie\",\"namespace\":\"org.acme.kafka.quarkus\",\"fields\":[{\"name\":\"title\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"}},{\"name\":\"year\",\"type\":\"int\"}]}\r\n\tat org.apache.avro.Schema.getElementType(Schema.java:370)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:689)\r\n\tat com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:774)\r\n\t... 28 more\r\n```\n\n### How to Reproduce?\n\nhttps://github.com/briancullen/quakus-avro-sample\r\n\r\nSteps to Reproduce:\r\n1. Check out one of the working branches (either confluent/working or apicurio/working).\r\n2. Start the consumer with quarkusDev\r\n3. Start the producer with quarkusDev\r\n4. Execute `srcipts/run_consumer.sh` in one terminal\r\n5. Execute `scripts/emit_movies.sh`\r\n6. Check the consumer to see the messages have arrived successfully.\r\n7. Switch to one of the failing branches (either confluent/failing or apicurio/failing).\r\n8. Do a clean build and remove any unstaged files.\r\n9. Repeat steps 2 - 5\r\n10. Check the logs for the producer and there should be errors.\n\n### Output of `uname -a` or `ver`\n\nLinux host 5.19.0-35-generic #36~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Feb 17 15:17:25 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\n\n### Output of `java -version`\n\nopenjdk version \"17.0.2\" 2022-01-18\r\nOpenJDK Runtime Environment (build 17.0.2+8-86)\r\nOpenJDK 64-Bit Server VM (build 17.0.2+8-86, mixed mode, sharing)\r\n\n\n### GraalVM version (if different from Java)\n\n_No response_\n\n### Quarkus version or git rev\n\n> 2.8\n\n### Build tool (ie. output of `mvnw --version` or `gradlew --version`)\n\n```\r\n------------------------------------------------------------\r\nGradle 7.2\r\n------------------------------------------------------------\r\n\r\nBuild time:   2021-08-17 09:59:03 UTC\r\nRevision:     a773786b58bb28710e3dc96c4d1a7063628952ad\r\n\r\nKotlin:       1.5.21\r\nGroovy:       3.0.8\r\nAnt:          Apache Ant(TM) version 1.10.9 compiled on September 27 2020\r\nJVM:          17.0.2 (Oracle Corporation 17.0.2+8-86)\r\nOS:           Linux 5.19.0-35-generic amd64\r\n```\n\n### Additional information\n\n_No response_",
  "reactions": {
    "url": "https://api.github.com/repos/quarkusio/quarkus/issues/31650/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/quarkusio/quarkus/issues/31650/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
